# -*- coding: utf-8 -*-
"""submission1-NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/141Mp2vwPN6mF2HU70j5GYV6nw5xcw0e8
"""

#download dataset
!wget --no-check-certificate \
http://fahmifuady.site/wp-content/uploads/2020/09/dataset_sms_v3.zip \
-O dataset_sms_v3.zip

# ekstrak file zip
import os
import zipfile

fzip = '/content/dataset_sms_v3.zip'
ekstrak = zipfile.ZipFile(fzip, 'r')
ekstrak.extractall('/content')

import pandas as pd
df = pd.read_csv('dataset_sms_v3.zip')
df.info()

df.head

# melakukan one-hot-encoding dan membuat dataset baru
category = pd.get_dummies(df.label)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='label')
df_baru

#Penjelasan Label 
#0: sms normal (1138)
#1: sms spam (670)
#2: promo (478)
#total = 1138 + 670 + 478 = 2286

df_baru.columns

# ubah dari dataframe jadi numpy array
isisms = df_baru['Teks'].values
label = df_baru[[0, 1, 2]].values

#train test split
from sklearn.model_selection import train_test_split
sms_train, sms_test, label_train, label_test = train_test_split(isisms, label, test_size=0.2)

#fungsi tokenizer
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(sms_train) 
tokenizer.fit_on_texts(sms_test)

seq_train = tokenizer.texts_to_sequences(sms_train)
seq_test  = tokenizer.texts_to_sequences(sms_test)

pad_train = pad_sequences(seq_train)
pad_test  = pad_sequences(seq_test)

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=6000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.summary()

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.90):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()


num_epoch = 30
history = model.fit(pad_train, label_train, epochs=num_epoch,
                    validation_data=(pad_test, label_test), verbose=2, callbacks=[callbacks])

# liat grafik
import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validasion Accuracy')
plt.title('Model accuracy')
plt.ylabel('accuracy')
plt.xlabel('Epoch')
plt.legend(loc='lower right')
plt.show()